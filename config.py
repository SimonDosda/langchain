# Model configuration
MODEL_CONFIG = {
    "name": "llama-2-7b-chat.Q4_K_M.gguf",
    "max_new_tokens": 512,
    "temperature": 0.7,
}

# Paths
MODELS_DIR = "models" 